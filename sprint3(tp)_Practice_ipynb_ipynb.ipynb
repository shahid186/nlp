{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3IPZ58-O2Aj"
   },
   "source": [
    "Task 1: Print the first 15 stop words provided by the library, find the total numbers of stop words available in the SpaCy library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "csjfr6hBOY_a",
    "outputId": "9adfd5f7-a495-4bc9-c4a4-8362f4801b80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First fifteen stop words : ['former', 'whereby', 'ever', 'up', 'your', 'sometimes', 'â€™s', 'beyond', 'here', 'whereas', 'indeed', 'though', 'six', 'somehow', 'name']\n",
      "Number of stop words : 326\n"
     ]
    }
   ],
   "source": [
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "print(\"First fifteen stop words : %s\" % list(spacy_stopwords)[:15])\n",
    "print(\"Number of stop words : %d\" % len(spacy_stopwords))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCjQ03kvPmVt"
   },
   "source": [
    "Task 2: Apply the Stemming and Lemmatization, which token gives better output and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XL929XgQPsYh",
    "outputId": "bec3fb4c-f347-45e3-abdd-7e3573cbd387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cries-->cri\n",
      "this-->this\n",
      "lied-->lie\n",
      "computing-->comput\n",
      "organizing-->organ\n",
      "matches-->match\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import snowball\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer (language = 'english')\n",
    "tokens = ['cries','this','lied','computing','organizing','matches']\n",
    "for token in tokens:\n",
    "  print(token + \"-->\" + stemmer.stem(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cries-->cri\n",
      "sweet-->sweet\n",
      "kied-->kie\n",
      "lied-->lie\n",
      "coumputing-->coumput\n",
      "matches-->match\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import snowball\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "s=SnowballStemmer(language='english')\n",
    "token=['cries','sweet','kied','lied','coumputing','matches']\n",
    "for token in token:\n",
    "    print(token + \"-->\" + stemmer.stem(token))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nka7eWdWQhAx"
   },
   "source": [
    "Conclusion: Here we can se the 'words : this, lied, and matches' gives better output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEl5SlflRLT-"
   },
   "source": [
    "Task 3: write the output aftr removing the stop words\n",
    "\n",
    "Task 3.a: Impute text file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "_M91dQhYQgE6",
    "outputId": "64b45df9-ce98-4ffa-ed63-7d07db972fac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-2c5c14ad-cf2f-4ef2-9c08-61ae1fc9fc2b\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-2c5c14ad-cf2f-4ef2-9c08-61ae1fc9fc2b\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving DS3_C2_S3_ScifiscriptsIntro_Data_Practice.txt to DS3_C2_S3_ScifiscriptsIntro_Data_Practice.txt\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "upload = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xqTkgIkzRmz1",
    "outputId": "6048fb08-b323-4df9-f2a6-d9517403d795"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'DS3_C2_S3_ScifiscriptsIntro_Data_Practice.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDS3_C2_S3_ScifiscriptsIntro_Data_Practice.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m content \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(content)\n",
      "File \u001b[1;32m~\\anaconda3\\New folder\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'DS3_C2_S3_ScifiscriptsIntro_Data_Practice.txt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "f = open(\"DS3_C2_S3_ScifiscriptsIntro_Data_Practice.txt\")\n",
    "content = f.read()\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "MSXWGmUlRm1Y",
    "outputId": "b5688ae5-4638-4b94-f9d9-b6b03f0fea34"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Note from poster to Kubrick newsgroup:\\n\\nI found this on a bbs a while ago and I thought I\\'d pass it along to all \\nof you Kubrick freaks out there.\\n\\n02/23/89\\nTranscriber\\'s note:\\n\\nFor all you Clarke/Kubrick/2001 fans,\\n\\nI found the original paper copy of this screenplay a while back and felt \\ncompelled to transcribe it to disk and upload it to various bulletin \\nboards for the enjoyment of all.\\n\\nThe final movie deviates from this screenplay in a number of interesting \\nways. I\\'ve tried to maintain the format of the original document except \\nthe number of lines per page of the original. In order to reduce the \\nlength of this file I\\'ve used a bar of \"------\" to delimit the pages as \\nthere was a lot of whitespace per original screenplay page.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = str(content)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pb-h7KbcSMZB"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OkFRsDsiRm4E",
    "outputId": "51c854b9-a055-4b49-a93b-1cf9d5c0927f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "Filtered Sentences : [Note, poster, Kubrick, newsgroup, :, \n",
      "\n",
      ", found, bbs, ago, thought, pass, \n",
      ", Kubrick, freaks, ., \n",
      "\n",
      ", 02/23/89, \n",
      ", Transcriber, note, :, \n",
      "\n",
      ", Clarke, /, Kubrick/2001, fans, ,, \n",
      "\n",
      ", found, original, paper, copy, screenplay, felt, \n",
      ", compelled, transcribe, disk, upload, bulletin, \n",
      ", boards, enjoyment, ., \n",
      "\n",
      ", final, movie, deviates, screenplay, number, interesting, \n",
      ", ways, ., tried, maintain, format, original, document, \n",
      ", number, lines, page, original, ., order, reduce, \n",
      ", length, file, bar, \", ------, \", delimit, pages, \n",
      ", lot, whitespace, original, screenplay, page, ., \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "filtered_sent = []\n",
    "doc = nlp(text) # nlp : tokenization, lemmatization, etc..\n",
    "for word in doc:\n",
    "  if word.is_stop == False:\n",
    "    filtered_sent.append(word)\n",
    "print(\"\\n \\nFiltered Sentences :\", filtered_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9Kcy7CeSfkC"
   },
   "source": [
    "Task 3b: FIve sentence of your choice using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKjQoGaiRm5V",
    "outputId": "7cf492b4-8c0f-416c-fa88-3364bd6dc4ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'on', \"'s\", 'herein', 'nevertheless', 'next', 'amongst', 'side', 'â€˜ll', 'same', 'elsewhere', 'or', 'were', 'put', 'thereby', 'wherever', 'seem', 'â€˜s', 'not', 'nâ€™t', 'herself', 'whereby', 'enough', 'latterly', 'who', 'will', 'noone', 'even', 'my_new_stopwords3', 'just', 'it', 'almost', 'below', 'various', 'through', 'should', 'did', 'onto', 'â€˜re', 'be', 'anyhow', 'alone', 'nobody', 'twenty', 'my_new_stopwords5', 'been', 'â€™ve', 'doing', 'must', 'â€™d', 'never', 'sixty', 'afterwards', 'are', 'hereupon', 'her', 'forty', 'itself', 'ever', 'as', 'toward', 'though', 'either', 'get', 'nothing', 'see', 'here', 'off', 'regarding', 'yourselves', 'upon', 'wherein', 'everyone', 'out', 'go', 'eight', 'him', 'whatever', 'thence', 'too', \"n't\", 'two', 'something', 'sometime', 'over', 'does', 'via', 'and', 'himself', 'what', 'how', 'there', 'also', 'could', 'fifty', 'my_new_stopwords4', 'his', 'somewhere', 'ourselves', 'why', 'often', 'few', 'others', 'so', 'well', 'behind', 'me', 'might', 'whoever', 'keep', 'another', 'six', 'every', 'although', 'mostly', 'first', 'empty', 'nowhere', 'nor', 'therein', 'since', 'hereafter', 'do', 'made', 'former', 'they', 'an', 'anywhere', 'under', 'whether', 'we', 'take', 'themselves', 'three', 'hence', 'this', 'while', \"'m\", 'across', 'both', 'becoming', 'by', 'above', 'become', 'front', 'with', 'â€™s', 'yourself', 'beside', 'yours', 'â€˜d', 'thereupon', 'seems', 'own', 'quite', 'i', 'name', 'per', 'cannot', \"'d\", 'seemed', 'he', 'used', 'about', 'ours', 'back', 'serious', 'of', 'several', 'our', 'myself', 'until', 'among', 'because', 'can', 'give', 'which', 'neither', \"'ve\", 'thru', 'fifteen', 'other', 'done', 'hundred', 'more', 'is', 'amount', 'each', 'around', 'whereafter', 'between', 'ca', 'again', 'always', 'none', 'throughout', 'your', 'to', 'when', 'whence', 'whom', 'rather', 'most', 'beyond', 'less', 'may', 'against', 'during', 'a', 'all', 'into', 'us', 'seeming', 'its', 'she', \"'ll\", 'whole', 'nine', 'would', 'now', 'them', 'together', 'once', 'have', 'my_new_stopwords2', 'became', 'â€™re', 'only', 'except', 'hereby', 'bottom', 'using', 'somehow', 'for', 'was', \"'re\", 'at', 'everything', 'everywhere', 'call', 'if', 'show', 'due', 'latter', 'top', 'part', 'make', 'still', 'such', 'being', 'these', 'then', 'no', 'sometimes', 'please', 'already', 'up', 'had', 'however', 'formerly', 'besides', 'least', 'than', 'eleven', 'otherwise', 'towards', 'namely', 'my', 'last', 'mine', 'therefore', 'â€˜m', 'really', 'ten', 'thereafter', 'you', 'in', 'say', 'thus', 'someone', 'nâ€˜t', 'whenever', 'twelve', 'the', 'further', 'becomes', 'unless', 'within', 'much', 'â€˜ve', 'full', 'indeed', 'has', 'where', 'after', 'third', 'my_new_stopwords1', 'without', 'move', 'five', 'those', 'that', 'anything', 'else', 'whither', 'yet', 'whose', 'their', 'whereupon', 'before', 'any', 'hers', 'four', 'some', 'whereas', 'very', 'many', 'anyone', 'beforehand', 'â€™m', 'am', 're', 'but', 'moreover', 'meanwhile', 'anyway', 'â€™ll', 'perhaps', 'along', 'down', 'from', 'one'}\n"
     ]
    }
   ],
   "source": [
    "nlp.Defaults.stop_words |={\"my_new_stopwords1\", \"my_new_stopwords2\",\"my_new_stopwords3\",\"my_new_stopwords4\",\"my_new_stopwords5\"}\n",
    "\n",
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyUUuD96TNnO"
   },
   "source": [
    "Removing the stop words from Default data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VGTMXbrLRm8_",
    "outputId": "2e1a9b91-d4bd-4fda-dd53-79250465911c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'on', \"'s\", 'herein', 'nevertheless', 'next', 'amongst', 'side', 'â€˜ll', 'same', 'elsewhere', 'or', 'were', 'put', 'thereby', 'wherever', 'seem', 'â€˜s', 'not', 'nâ€™t', 'herself', 'whereby', 'enough', 'latterly', 'who', 'will', 'noone', 'even', 'my_new_stopwords3', 'just', 'it', 'almost', 'below', 'various', 'through', 'should', 'did', 'onto', 'â€˜re', 'be', 'anyhow', 'alone', 'nobody', 'twenty', 'my_new_stopwords5', 'been', 'â€™ve', 'doing', 'must', 'â€™d', 'never', 'sixty', 'afterwards', 'are', 'hereupon', 'her', 'forty', 'itself', 'ever', 'as', 'toward', 'though', 'either', 'get', 'nothing', 'see', 'here', 'off', 'regarding', 'yourselves', 'upon', 'wherein', 'everyone', 'out', 'go', 'eight', 'him', 'whatever', 'thence', 'too', \"n't\", 'two', 'something', 'sometime', 'over', 'does', 'via', 'and', 'himself', 'what', 'how', 'there', 'also', 'could', 'fifty', 'my_new_stopwords4', 'his', 'somewhere', 'ourselves', 'why', 'often', 'few', 'others', 'so', 'well', 'behind', 'me', 'might', 'whoever', 'keep', 'another', 'six', 'every', 'although', 'mostly', 'first', 'empty', 'nowhere', 'nor', 'therein', 'since', 'hereafter', 'do', 'made', 'former', 'they', 'an', 'anywhere', 'under', 'whether', 'we', 'take', 'themselves', 'three', 'hence', 'this', 'while', \"'m\", 'across', 'both', 'becoming', 'by', 'above', 'become', 'front', 'with', 'â€™s', 'yourself', 'beside', 'yours', 'â€˜d', 'thereupon', 'seems', 'own', 'quite', 'i', 'name', 'per', 'cannot', \"'d\", 'seemed', 'he', 'used', 'about', 'ours', 'back', 'serious', 'of', 'several', 'our', 'myself', 'until', 'among', 'because', 'can', 'give', 'which', 'neither', \"'ve\", 'thru', 'fifteen', 'other', 'done', 'hundred', 'more', 'is', 'amount', 'each', 'around', 'whereafter', 'between', 'ca', 'again', 'always', 'none', 'throughout', 'your', 'to', 'when', 'whence', 'whom', 'rather', 'most', 'beyond', 'less', 'may', 'against', 'during', 'a', 'all', 'into', 'us', 'seeming', 'its', 'she', \"'ll\", 'whole', 'nine', 'would', 'now', 'them', 'together', 'once', 'have', 'my_new_stopwords2', 'became', 'â€™re', 'only', 'except', 'hereby', 'bottom', 'using', 'somehow', 'for', 'was', \"'re\", 'at', 'everything', 'everywhere', 'call', 'if', 'show', 'due', 'latter', 'top', 'part', 'make', 'still', 'such', 'being', 'these', 'then', 'no', 'please', 'already', 'up', 'had', 'however', 'formerly', 'besides', 'least', 'than', 'eleven', 'otherwise', 'towards', 'namely', 'my', 'last', 'mine', 'therefore', 'â€˜m', 'really', 'ten', 'thereafter', 'you', 'in', 'say', 'thus', 'someone', 'nâ€˜t', 'whenever', 'twelve', 'the', 'further', 'becomes', 'unless', 'within', 'much', 'â€˜ve', 'full', 'indeed', 'has', 'where', 'after', 'third', 'my_new_stopwords1', 'without', 'move', 'five', 'those', 'that', 'anything', 'else', 'whither', 'yet', 'whose', 'their', 'whereupon', 'before', 'any', 'hers', 'four', 'some', 'very', 'many', 'anyone', 'beforehand', 'â€™m', 'am', 're', 'but', 'moreover', 'meanwhile', 'anyway', 'â€™ll', 'perhaps', 'along', 'down', 'from', 'one'}\n"
     ]
    }
   ],
   "source": [
    "nlp.Defaults.stop_words -= {\"sometimes\", \"whereas\"}\n",
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UelwRpjnTcoR"
   },
   "source": [
    "Task 4: For each word in the sentence given below, write the corresponding POS nd tag it with  description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YyYC_4ZBTysJ",
    "outputId": "cf1d979e-324b-4347-fe9c-a1eff4df2034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bryan \t PROPN \t NNP\n",
      "visited \t VERB \t VBD\n",
      "to \t ADP \t IN\n",
      "his \t PRON \t PRP$\n",
      "friend \t NOUN \t NN\n",
      "for \t ADP \t IN\n",
      "a \t DET \t DT\n",
      "while \t NOUN \t NN\n",
      "and \t CCONJ \t CC\n",
      "then \t ADV \t RB\n",
      "went \t VERB \t VBD\n",
      "home \t ADV \t RB\n",
      "at \t ADP \t IN\n",
      "10 \t NUM \t CD\n",
      "p.m. \t NOUN \t NN\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Bryan visited to his friend for a while and then went home at 10 p.m. ')\n",
    "\n",
    "for word in doc:\n",
    "  print(word.text, '\\t', word.pos_,'\\t', word.tag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOoU_skuUr8P"
   },
   "source": [
    "Task 5: For the \"Random.txt.file\" , which words are proper nouns nd numerics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "_mkUHi8XVLRV",
    "outputId": "47c37d81-6be5-4ced-e414-e99f6e389a90"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-d094f6c0-3b9b-452a-b13b-e89731cfaefd\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-d094f6c0-3b9b-452a-b13b-e89731cfaefd\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving DS3_C2_S3_Random_Data_Practice.txt to DS3_C2_S3_Random_Data_Practice.txt\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "upload = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-evi9_-Tyu8",
    "outputId": "f83ad1b1-695a-4d83-a711-5d01f7f9ae88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PADUA HIGH SCHOOL - DAY\n",
      "Revision November 12, 1997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "f = open(\"DS3_C2_S3_Random_Data_Practice.txt\")\n",
    "content2 = f.read()\n",
    "print(content2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "AkBKdSVYTyx5",
    "outputId": "8251c811-0109-4c20-bbce-1a318e59677a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'PADUA HIGH SCHOOL - DAY\\nRevision November 12, 1997\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = str(content2)\n",
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWLpgHSWVbuR"
   },
   "outputs": [],
   "source": [
    "text2 = str(content2) #converting to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VckN3CkPXYWc"
   },
   "outputs": [],
   "source": [
    "doc2 = nlp(text2) #tokkenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "POeicbR-XYYG",
    "outputId": "0f9494a6-d804-4e26-99bb-182b1310598e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proper noun words are [SCHOOL, DAY, Revision, November]\n"
     ]
    }
   ],
   "source": [
    "a=[] #empty list to add Pronoun words\n",
    "for word in doc2:\n",
    "  if word.pos_ == 'PROPN':\n",
    "    a.append(word) #adding only pronoun word\n",
    "print(\"Proper noun words are {}\".format(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fh-1RwqMXYbP",
    "outputId": "84e021d5-e77f-4d69-88b9-c0f9042fdd25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical words are [12, 1997]\n"
     ]
    }
   ],
   "source": [
    "b=[] #empty list to add numerical words\n",
    "for word in doc2:\n",
    "  if word.pos_ =='NUM':\n",
    "    b.append(word)\n",
    "print(\"numerical words are {}\".format(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BFEC9OzYPxD"
   },
   "source": [
    "Task 6: Add you own 5 stop words in spaCy and print the result. Remove these four stop words from the default spaCy and print the result again:\n",
    "\n",
    "'always','never','between','becomes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JVNZ348QYSK6",
    "outputId": "827ded65-2df2-41c5-f727-50d1ecd83be2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'on', \"'s\", 'herein', 'nevertheless', 'next', 'amongst', 'side', 'â€˜ll', 'same', 'elsewhere', 'or', 'were', 'put', 'thereby', 'wherever', 'seem', 'â€˜s', 'not', 'nâ€™t', 'herself', 'whereby', 'enough', 'latterly', 'who', 'will', 'noone', 'even', 'my_new_stopwords3', 'just', 'it', 'almost', 'below', 'various', 'through', 'should', 'did', 'onto', 'â€˜re', 'be', 'anyhow', 'alone', 'nobody', 'twenty', 'my_new_stopwords5', 'been', 'â€™ve', 'doing', 'must', 'â€™d', 'never', 'sixty', 'afterwards', 'are', 'hereupon', 'her', 'forty', 'itself', 'ever', 'as', 'toward', 'though', 'either', 'get', 'nothing', 'see', 'here', 'off', 'regarding', 'yourselves', 'upon', 'wherein', 'everyone', 'out', 'go', 'eight', 'him', 'whatever', 'thence', 'too', \"n't\", 'two', 'something', 'sometime', 'over', 'does', 'via', 'and', 'himself', 'what', 'how', 'there', 'also', 'could', 'fifty', 'my_new_stopwords4', 'his', 'somewhere', 'ourselves', 'why', 'often', 'few', 'others', 'so', 'well', 'behind', 'me', 'might', 'whoever', 'keep', 'another', 'six', 'every', 'although', 'mostly', 'first', 'empty', 'nowhere', 'nor', 'therein', 'since', 'hereafter', 'do', 'made', 'former', 'they', 'an', 'anywhere', 'under', 'whether', 'we', 'take', 'themselves', 'three', 'hence', 'this', 'while', \"'m\", 'across', 'both', 'becoming', 'by', 'above', 'become', 'front', 'with', 'â€™s', 'yourself', 'beside', 'yours', 'â€˜d', 'thereupon', 'seems', 'own', 'quite', 'i', 'name', 'per', 'cannot', \"'d\", 'seemed', 'he', 'used', 'about', 'ours', 'back', 'serious', 'of', 'several', 'our', 'myself', 'until', 'among', 'because', 'can', 'give', 'which', 'neither', \"'ve\", 'thru', 'fifteen', 'other', 'done', 'hundred', 'more', 'is', 'amount', 'each', 'around', 'whereafter', 'between', 'ca', 'again', 'always', 'none', 'throughout', 'your', 'to', 'when', 'whence', 'whom', 'rather', 'most', 'beyond', 'less', 'may', 'against', 'during', 'a', 'all', 'into', 'us', 'seeming', 'its', 'she', \"'ll\", 'whole', 'nine', 'would', 'now', 'them', 'together', 'once', 'have', 'my_new_stopwords2', 'became', 'â€™re', 'only', 'except', 'hereby', 'bottom', 'using', 'somehow', 'for', 'was', \"'re\", 'at', 'everything', 'everywhere', 'call', 'if', 'show', 'due', 'latter', 'top', 'part', 'make', 'still', 'such', 'being', 'these', 'then', 'no', 'please', 'already', 'up', 'had', 'however', 'formerly', 'besides', 'least', 'than', 'eleven', 'otherwise', 'towards', 'namely', 'my', 'last', 'mine', 'therefore', 'â€˜m', 'really', 'ten', 'thereafter', 'you', 'in', 'say', 'thus', 'someone', 'nâ€˜t', 'whenever', 'twelve', 'the', 'further', 'becomes', 'unless', 'within', 'much', 'â€˜ve', 'full', 'indeed', 'has', 'where', 'after', 'third', 'my_new_stopwords1', 'without', 'move', 'five', 'those', 'that', 'anything', 'else', 'whither', 'yet', 'whose', 'their', 'whereupon', 'before', 'any', 'hers', 'four', 'some', 'very', 'many', 'anyone', 'beforehand', 'â€™m', 'am', 're', 'but', 'moreover', 'meanwhile', 'anyway', 'â€™ll', 'perhaps', 'along', 'down', 'from', 'one'}\n",
      "Length of Stop Words : 329\n"
     ]
    }
   ],
   "source": [
    "nlp.Defaults.stop_words |= {\"the\",\"and\",\"of\",\"to\",\"was\"} # for adding\n",
    "print(nlp.Defaults.stop_words)\n",
    "print(\"Length of Stop Words :\",len(nlp.Defaults.stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4MtsEFaIYSNW",
    "outputId": "2b51ab01-f470-427d-ab89-f608ebb82b1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'on', \"'s\", 'herein', 'nevertheless', 'next', 'amongst', 'side', 'â€˜ll', 'same', 'elsewhere', 'or', 'were', 'put', 'thereby', 'wherever', 'seem', 'â€˜s', 'not', 'nâ€™t', 'herself', 'whereby', 'enough', 'latterly', 'who', 'will', 'noone', 'even', 'my_new_stopwords3', 'just', 'it', 'almost', 'below', 'various', 'through', 'should', 'did', 'onto', 'â€˜re', 'be', 'anyhow', 'alone', 'nobody', 'twenty', 'my_new_stopwords5', 'been', 'â€™ve', 'doing', 'must', 'â€™d', 'sixty', 'afterwards', 'are', 'hereupon', 'her', 'forty', 'itself', 'ever', 'as', 'toward', 'though', 'either', 'get', 'nothing', 'see', 'here', 'off', 'regarding', 'yourselves', 'upon', 'wherein', 'everyone', 'out', 'go', 'eight', 'him', 'whatever', 'thence', 'too', \"n't\", 'two', 'something', 'sometime', 'over', 'does', 'via', 'and', 'himself', 'what', 'how', 'there', 'also', 'could', 'fifty', 'my_new_stopwords4', 'his', 'somewhere', 'ourselves', 'why', 'often', 'few', 'others', 'so', 'well', 'behind', 'me', 'might', 'whoever', 'keep', 'another', 'six', 'every', 'although', 'mostly', 'first', 'empty', 'nowhere', 'nor', 'therein', 'since', 'hereafter', 'do', 'made', 'former', 'they', 'an', 'anywhere', 'under', 'whether', 'we', 'take', 'themselves', 'three', 'hence', 'this', 'while', \"'m\", 'across', 'both', 'becoming', 'by', 'above', 'become', 'front', 'with', 'â€™s', 'yourself', 'beside', 'yours', 'â€˜d', 'thereupon', 'seems', 'own', 'quite', 'i', 'name', 'per', 'cannot', \"'d\", 'seemed', 'he', 'used', 'about', 'ours', 'back', 'serious', 'of', 'several', 'our', 'myself', 'until', 'among', 'because', 'can', 'give', 'which', 'neither', \"'ve\", 'thru', 'fifteen', 'other', 'done', 'hundred', 'more', 'is', 'amount', 'each', 'around', 'whereafter', 'ca', 'again', 'none', 'throughout', 'your', 'to', 'when', 'whence', 'whom', 'rather', 'most', 'beyond', 'less', 'may', 'against', 'during', 'a', 'all', 'into', 'us', 'seeming', 'its', 'she', \"'ll\", 'whole', 'nine', 'would', 'now', 'them', 'together', 'once', 'have', 'my_new_stopwords2', 'became', 'â€™re', 'only', 'except', 'hereby', 'bottom', 'using', 'somehow', 'for', 'was', \"'re\", 'at', 'everything', 'everywhere', 'call', 'if', 'show', 'due', 'latter', 'top', 'part', 'make', 'still', 'such', 'being', 'these', 'then', 'no', 'please', 'already', 'up', 'had', 'however', 'formerly', 'besides', 'least', 'than', 'eleven', 'otherwise', 'towards', 'namely', 'my', 'last', 'mine', 'therefore', 'â€˜m', 'really', 'ten', 'thereafter', 'you', 'in', 'say', 'thus', 'someone', 'nâ€˜t', 'whenever', 'twelve', 'the', 'further', 'unless', 'within', 'much', 'â€˜ve', 'full', 'indeed', 'has', 'where', 'after', 'third', 'my_new_stopwords1', 'without', 'move', 'five', 'those', 'that', 'anything', 'else', 'whither', 'yet', 'whose', 'their', 'whereupon', 'before', 'any', 'hers', 'four', 'some', 'very', 'many', 'anyone', 'beforehand', 'â€™m', 'am', 're', 'but', 'moreover', 'meanwhile', 'anyway', 'â€™ll', 'perhaps', 'along', 'down', 'from', 'one'}\n",
      "Length of Stop Words : 325\n"
     ]
    }
   ],
   "source": [
    "nlp.Defaults.stop_words -= {\"always\",\"never\",\"between\",\"becomes\"} # for removing\n",
    "print(nlp.Defaults.stop_words)\n",
    "print(\"Length of Stop Words :\",len(nlp.Defaults.stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dy2APYO8ZC82"
   },
   "source": [
    "Task 7: Using spaCy follow below:\n",
    "\n",
    "1) Apply tokkenization\n",
    "\n",
    "2) Remove stop words from the input\n",
    "\n",
    "3) Apply lemmatization\n",
    "\n",
    "4) Apply POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "QvKpkpOmYSQW",
    "outputId": "f6b7f50f-e80e-4596-83c7-ccd5c1b3f22b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-feb36111-5bba-4c2a-a756-d1ce743f16f3\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-feb36111-5bba-4c2a-a756-d1ce743f16f3\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving DS3_C2_S3_Sample_Data_Practice.txt to DS3_C2_S3_Sample_Data_Practice.txt\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files #to upload dataset\n",
    "upload3 = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36bq14AdYSTN",
    "outputId": "8cc702e2-69e8-4c93-e481-e9310816f634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PADUA HIGH SCHOOL - DAY\n",
      "Revision November 12, 1997\n",
      "I hope dinner's ready because I only have ten minutes before Mrs. Johnson squirts out a screamer.\n",
      "He grabs the mail and rifles through it, as he bends down to kiss Sharon on the cheek.\n",
      "MICHAEL- C'mon. I'm supposed to give you the tour. They head out of the office\n",
      "MICHAEL (continuing)- So -- which Dakota you from?\n",
      "          \n",
      "                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "f3 = open(\"DS3_C2_S3_Sample_Data_Practice.txt\") #reading dataset\n",
    "content3 = f3.read()\n",
    "print(content3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-1i6j8fYSdv",
    "outputId": "9964094a-fa43-4b7d-9990-7a61cec41e25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nlp(content3) #tokkenization\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fxmr9vZLXYc4",
    "outputId": "c0850033-f17e-456e-c2e0-14553ec066b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Filtered Sentence:  [PADUA, HIGH, SCHOOL, -, DAY, \n",
      ", Revision, November, 12, ,, 1997, \n",
      ", hope, dinner, ready, minutes, Mrs., Johnson, squirts, screamer, ., \n",
      ", grabs, mail, rifles, ,, bends, kiss, Sharon, cheek, ., \n",
      ", MICHAEL-, C'm, ., supposed, tour, ., head, office, \n",
      ", MICHAEL, (, continuing)-, --, Dakota, ?, \n",
      "          \n",
      "                                 \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#removing stop words\n",
    "filtered_sent = []\n",
    "doc = nlp(text)\n",
    "for word in doc:\n",
    "  if word.is_stop == False:\n",
    "    filtered_sent.append(word)\n",
    "\n",
    "print(\"\\n\\nFiltered Sentence: \",filtered_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60HN6IogXYgH",
    "outputId": "f0a15d96-cac1-4cb8-ff25-4b04f148da37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PADUA --> PADUA\n",
      "HIGH --> high\n",
      "SCHOOL --> SCHOOL\n",
      "- --> -\n",
      "DAY --> DAY\n",
      "\n",
      " --> \n",
      "\n",
      "Revision --> Revision\n",
      "November --> November\n",
      "12 --> 12\n",
      ", --> ,\n",
      "1997 --> 1997\n",
      "\n",
      " --> \n",
      "\n",
      "hope --> hope\n",
      "dinner --> dinner\n",
      "ready --> ready\n",
      "minutes --> minute\n",
      "Mrs. --> Mrs.\n",
      "Johnson --> Johnson\n",
      "squirts --> squirt\n",
      "screamer --> screamer\n",
      ". --> .\n",
      "\n",
      " --> \n",
      "\n",
      "grabs --> grab\n",
      "mail --> mail\n",
      "rifles --> rifle\n",
      ", --> ,\n",
      "bends --> bend\n",
      "kiss --> kiss\n",
      "Sharon --> Sharon\n",
      "cheek --> cheek\n",
      ". --> .\n",
      "\n",
      " --> \n",
      "\n",
      "MICHAEL- --> MICHAEL-\n",
      "C'm --> come\n",
      ". --> .\n",
      "supposed --> suppose\n",
      "tour --> tour\n",
      ". --> .\n",
      "head --> head\n",
      "office --> office\n",
      "\n",
      " --> \n",
      "\n",
      "MICHAEL --> MICHAEL\n",
      "( --> (\n",
      "continuing)- --> continuing)-\n",
      "-- --> --\n",
      "Dakota --> Dakota\n",
      "? --> ?\n",
      "\n",
      "          \n",
      "                                 \n",
      " --> \n",
      "          \n",
      "                                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lammitization\n",
    "for word in filtered_sent:\n",
    "  print(word.text, \"-->\", word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gc8tEPbmXYi1",
    "outputId": "b3944a7c-f3ef-4755-dffd-fdab85c1aa81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PADUA --> VERB\n",
      "HIGH --> ADJ\n",
      "SCHOOL --> PROPN\n",
      "- --> PUNCT\n",
      "DAY --> PROPN\n",
      "\n",
      " --> SPACE\n",
      "Revision --> PROPN\n",
      "November --> PROPN\n",
      "12 --> NUM\n",
      ", --> PUNCT\n",
      "1997 --> NUM\n",
      "\n",
      " --> SPACE\n",
      "hope --> VERB\n",
      "dinner --> NOUN\n",
      "ready --> ADJ\n",
      "minutes --> NOUN\n",
      "Mrs. --> PROPN\n",
      "Johnson --> PROPN\n",
      "squirts --> VERB\n",
      "screamer --> NOUN\n",
      ". --> PUNCT\n",
      "\n",
      " --> SPACE\n",
      "grabs --> VERB\n",
      "mail --> NOUN\n",
      "rifles --> NOUN\n",
      ", --> PUNCT\n",
      "bends --> VERB\n",
      "kiss --> VERB\n",
      "Sharon --> PROPN\n",
      "cheek --> NOUN\n",
      ". --> PUNCT\n",
      "\n",
      " --> SPACE\n",
      "MICHAEL- --> PROPN\n",
      "C'm --> VERB\n",
      ". --> PUNCT\n",
      "supposed --> VERB\n",
      "tour --> NOUN\n",
      ". --> PUNCT\n",
      "head --> VERB\n",
      "office --> NOUN\n",
      "\n",
      " --> SPACE\n",
      "MICHAEL --> PROPN\n",
      "( --> PUNCT\n",
      "continuing)- --> NOUN\n",
      "-- --> PUNCT\n",
      "Dakota --> PROPN\n",
      "? --> PUNCT\n",
      "\n",
      "          \n",
      "                                 \n",
      " --> SPACE\n"
     ]
    }
   ],
   "source": [
    "# POS Tagging\n",
    "for word in filtered_sent:\n",
    "  print(word.text,\"-->\",word.pos_)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
