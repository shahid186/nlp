{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cd1daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy                                               # import spacy library\n",
    "from spacy.lang.en import English                          # importspecific model\n",
    "nlp = spacy.load(\"en_core_web_sm\")                         # load model\n",
    "import collections\n",
    "from typing import Dict,List,Tuple                         # import dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a317735",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c07077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 3), (1, 1), (2, 3), (3, 3), (4, 4), (5, 1), (6, 2), (7, 3), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)]\n"
     ]
    }
   ],
   "source": [
    "def text2bow(words: List[str],dictinory: Dict[str,int]) -> List[Tuple[int,int]]: # text to bow\n",
    "    word_frequences = collections.defaultdict(int)\n",
    "   \n",
    "    for word in words:\n",
    "        if word not in dictinory:            # check condition\n",
    "            dictinory[word]= len(dictinory)  # each word index and index location\n",
    "            \n",
    "        word_frequences[dictinory[word]] +=1\n",
    "        \n",
    "    return list(word_frequences.items())    # return word frequency\n",
    "sample_text ='Review 1: This movie is very scary and long. Review 2: This movie is not scary and is slow. Review 3: This movie is spooky and good.'\n",
    "dictionary = {}\n",
    "print(text2bow(sample_text.split(),dictionary)) #print bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90da32bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input text: \n",
      "Review 1: This movie is very scary and long. Review 2: This movie is not scary and is slow. Review 3: This movie is spooky and good.\n",
      "\n",
      "Dictionary: \n",
      "{'Review': 0, '1:': 1, 'This': 2, 'movie': 3, 'is': 4, 'very': 5, 'scary': 6, 'and': 7, 'long.': 8, '2:': 9, 'not': 10, 'slow.': 11, '3:': 12, 'spooky': 13, 'good.': 14}\n"
     ]
    }
   ],
   "source": [
    "print(\"input text: \\n{}\".format(sample_text)) # input data\n",
    "print(\"\\nDictionary: \\n{}\".format(dictionary))# dictionary value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4985e67",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c8733df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey siri\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher                    # import matcher\n",
    "nlp = spacy.load(\"en_core_web_sm\")                   # load model\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"LOWER\":'hey'},{'LOWER':'siri'}]         # add match id helloworld with no callback\n",
    "matcher.add(\"Hey siri\",[pattern])\n",
    "doc = nlp(\"Hey siri\")                               # input text with tokkenize\n",
    "matches = matcher(doc)\n",
    "for match_id,start,end in matches:                  # find match\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "    span = doc[start:end]\n",
    "    print(span.text)                                # print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25aa0ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, siri\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"LOWER\":'hey'},{\"IS_PUNCT\":True},{'LOWER':'siri'}]\n",
    "matcher.add(\"Hey, siri\",[pattern])\n",
    "doc = nlp(\"Hey, siri\")\n",
    "matches = matcher(doc)\n",
    "for match_id,start,end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "    span = doc[start:end]\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585c6a24",
   "metadata": {},
   "source": [
    "# TASK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23e3fffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Length:\n",
      " (96,)\n",
      "Word Vector Representation\n",
      " [-0.01291151 -0.63742214  0.6336341   0.7220289  -0.7089878  -0.2020278\n",
      " -0.21471749  1.7504792  -0.43238533 -0.75817096  1.8110483  -0.8448776\n",
      " -0.8092954  -0.60360026 -0.15348431  0.30619383 -0.9539893  -0.79956675\n",
      " -0.7785482  -0.8693065   0.21894354 -0.06897593  0.8038384   0.17259844\n",
      "  0.2581646   0.7076305   0.8857086   0.782564   -0.4451243   1.1322079\n",
      " -0.69896    -1.0962689   0.1928064   1.0511543  -0.6390506   0.26279163\n",
      "  1.7593797  -0.8621046   0.47793993  1.5560223  -0.92148495  1.457032\n",
      " -0.28774732  1.1776068  -0.6398139  -0.15469822  0.64170146  0.6397705\n",
      "  0.10651273 -0.5398765  -0.13111869 -1.6336241   0.9770989  -0.49307543\n",
      " -0.4739711  -0.433877   -0.22383378 -0.52839124  0.8471283  -0.24316812\n",
      " -1.392698    0.22927427 -0.29445207 -1.8478808  -0.7132102  -1.077588\n",
      " -0.26076427  0.51486564 -0.5803723  -0.91216826  0.24041569  0.5029696\n",
      "  0.4219088  -1.6083198  -0.07817796 -0.09576415  0.7770756  -0.04122347\n",
      "  0.6525791  -0.39792585  0.95907086 -0.16041932 -0.02049139 -1.1042901\n",
      " -0.09630179  0.4258653   0.14272809 -0.38179088 -0.7186223   0.6918746\n",
      " -0.37465477 -0.33817604  0.39940822  1.5588735  -0.6269769   0.10933062]\n",
      "Vector Length:\n",
      " (96,)\n",
      "Word Vector Representation\n",
      " [-0.48219478 -0.8879161   0.77188116 -0.09212857 -0.872227   -0.06087497\n",
      " -0.19773766  0.60087913  0.10527319 -0.521292    1.2793094   1.4865795\n",
      " -0.5602882  -0.68352735 -0.37648737  1.1974629  -0.65102154 -0.6749157\n",
      "  0.32830942 -0.07141492 -1.4182062   0.8189477  -0.7697373   0.13235147\n",
      "  0.68783486  0.14184943 -0.67017674  0.23376575 -0.48190784  1.1027646\n",
      " -0.43941343  0.01438388  0.3971234  -0.30096328 -0.48361817 -1.1059235\n",
      "  1.0644592   0.23570469  0.3536337  -1.7508998  -1.423107    0.7466299\n",
      " -0.92643535  0.13952743 -0.79238456  0.04731327  0.25721854  0.79803824\n",
      "  0.10066423  0.9858154  -1.1452986  -1.1978736   0.875546   -0.5886304\n",
      " -0.9412149  -0.8002951   0.93735677  0.10557401 -0.10572121 -0.18317658\n",
      " -1.0777463   1.2808043   0.08866367 -1.2707585  -1.0514246  -1.0393574\n",
      "  0.6482193   0.24688613  0.8412553  -0.04344732  0.9765717   1.5862397\n",
      "  0.7634014  -1.1051475   0.5845053   0.98328364 -0.83437675 -0.71610576\n",
      " -0.26160118 -0.25987047  0.52913356 -0.2520613  -1.7734828   0.19672889\n",
      " -1.1328119  -0.04406126 -0.18094997 -0.1844796  -0.87994385  1.2617023\n",
      " -0.74869466  0.43441767  1.5414302   0.7893902   0.11296847  0.5242842 ]\n",
      "Vector Length:\n",
      " (96,)\n",
      "Word Vector Representation\n",
      " [-0.72919613 -0.93858826  0.7890328   0.36545914 -0.45382163  0.19520926\n",
      "  0.42715502 -1.1640995   0.5606207  -1.0604131   1.3048911   1.0543224\n",
      " -0.99581563 -0.84921587 -1.1542796   0.17798582  0.36108023 -0.77407324\n",
      " -0.00446703 -0.01108103 -1.1228962   0.29787078 -1.8227218   0.68027556\n",
      "  0.08032517 -0.06465513  0.29591528  0.31131732 -0.5400094   0.27139106\n",
      " -0.37554833  0.87944806 -0.82009345  1.1500953  -0.18961984 -0.8219536\n",
      "  0.98609877 -0.4336438   0.01724015 -0.1533106  -1.6640887   0.9466558\n",
      " -1.10999     0.13889873 -0.23361269 -0.60636514 -0.732776    0.23582795\n",
      "  0.22540379  0.3724686  -0.12571344 -0.80252564  0.29503345  0.15230483\n",
      " -0.7438605  -0.22805548  0.80206025  0.5381145  -0.60066617  0.11447279\n",
      " -0.7500378  -0.38932443 -0.39014074 -0.8870872  -0.11783104 -0.5256261\n",
      " -0.21282873  1.7759534   0.1530866   2.2659054   1.6508703   0.9642472\n",
      "  0.9094777  -1.6882036   0.09743783  0.34422058  0.1035035  -0.11929873\n",
      " -0.19305742 -0.13666776 -0.36951676 -0.7549172   0.95351124  0.2709204\n",
      " -0.95452034  0.03104326  0.18716896  0.2521941  -0.69262433  1.7984687\n",
      "  0.45977017  0.5054407   0.9179981   0.46033585 -0.05572583 -0.07003435]\n",
      "Vector Length:\n",
      " (96,)\n",
      "Word Vector Representation\n",
      " [-1.01247287e+00 -8.71406555e-01 -1.13163638e+00  4.53890562e-02\n",
      "  8.36671948e-01 -5.10308146e-02 -2.93771863e-01  6.07491970e-01\n",
      "  2.35986471e-01 -5.18576503e-01  2.57586122e-01 -4.50986475e-01\n",
      "  3.46603692e-01  8.40262353e-01 -1.12680268e+00  3.23443949e-01\n",
      " -4.81796205e-01 -2.27388591e-01  4.97695446e-01  5.93989611e-01\n",
      "  6.56840801e-02  1.39822766e-01 -2.34026074e+00  4.96065438e-01\n",
      " -1.21557820e+00 -3.55896831e-01  1.37245178e+00  3.63409251e-01\n",
      " -3.57755989e-01  1.21780932e-01  2.26828247e-01  3.54993939e-02\n",
      " -1.45519763e-01  7.29695857e-01 -9.28744853e-01 -6.98245049e-01\n",
      "  7.28879333e-01  1.67400670e+00  1.58425868e-01 -7.07785130e-01\n",
      " -7.85632014e-01  5.13735712e-01 -8.69293571e-01 -7.36907840e-01\n",
      "  2.02924132e-01  1.60426825e-01 -2.26010188e-01 -1.24067640e+00\n",
      "  8.42003673e-02  2.74294019e-01  1.69777721e-01  8.76462102e-01\n",
      "  1.17153324e-01 -4.59485561e-01 -2.42060423e-03  1.23875213e+00\n",
      "  5.18011600e-02  4.93470311e-01  2.91320771e-01  2.49805272e-01\n",
      "  1.53806239e-01 -2.13347816e+00 -5.89362860e-01  6.45250976e-02\n",
      "  8.77180696e-03 -1.13070339e-01  1.39914215e+00  1.20535418e-01\n",
      " -2.27618024e-01 -8.82800758e-01  3.79744977e-01  7.23721266e-01\n",
      " -5.54815054e-01 -5.04451096e-01 -2.72659093e-01 -4.54761416e-01\n",
      " -9.03766453e-01  3.27999026e-01 -7.35947430e-01 -6.10857010e-01\n",
      "  5.83473206e-01 -1.68083012e-01 -6.96939230e-02 -1.07245609e-01\n",
      " -1.27255940e+00  1.45942748e+00  3.90473664e-01  5.56055248e-01\n",
      " -5.28663218e-01  5.21860838e-01 -8.23909283e-01  5.38776934e-01\n",
      "  2.89312267e+00  9.73923802e-02 -2.61319637e-01  5.15976429e-01]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('apple orange pikkstn German')                  # input \n",
    "for token in doc:\n",
    "    print('Vector Length:\\n',token.vector.shape)          # length of vector\n",
    "    print('Word Vector Representation\\n',token.vector)    # print output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e7bdb1",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7efa79c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched based on lowercase token text:  rotten mangoes\n",
      "Matched based on lowercase token text:  sweet oranges\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher                              # import matcher\n",
    "matcher = PhraseMatcher(nlp.vocab,attr='LOWER')                      # load model\n",
    "terms = [\"ROTTEN mangoes\",\"sweet oranges\"]                           \n",
    "patterns = [nlp.make_doc(text) for text in terms]\n",
    "matcher.add(\"Fruits\",patterns)\n",
    "doc = nlp(\"Do not put rotten mangoes and sweet oranges together\")\n",
    "for match_id,start,end in matcher(doc):\n",
    "    print(\"Matched based on lowercase token text: \",doc[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207de278",
   "metadata": {},
   "source": [
    "# Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec4a02c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector length: \n",
      " (96,)\n",
      "Word Vector Representation:\n",
      " [-0.9435841  -0.13761951 -0.41831952 -0.15897208 -0.4302298  -0.04438317\n",
      "  2.3614748   0.6231054   0.0122031  -0.79678786  2.2164228   1.634094\n",
      " -0.46185458  0.47664887 -1.5722715  -0.852956    0.7579042   1.0350271\n",
      " -0.91913295 -0.5994303  -0.90215635  0.22339064  0.22972403 -1.2096164\n",
      " -0.62598217 -0.50422657 -0.544212   -0.20867735 -1.2677568   0.25655213\n",
      " -0.12779951 -0.6996877  -0.82510996 -0.14156663 -0.42306674 -0.6998179\n",
      " -0.99681437 -0.4949299  -1.0885243   1.7996302  -0.9437039   0.33264816\n",
      "  0.03097375  1.1109407  -0.7527068  -0.53995335  0.8292919   3.7861528\n",
      " -0.08327061 -0.09838206 -1.1750913  -1.1477796   1.4207778  -1.2538137\n",
      "  0.56365967 -1.1316081   0.8606243  -0.9959679   0.16899098  1.0195899\n",
      "  1.4902151   0.12664063  0.5253415  -0.46430543  1.2312306   0.4858403\n",
      " -0.897334   -0.46871835 -1.1867027  -1.9095289   0.29641783 -0.31166956\n",
      "  1.0440685  -0.06307149 -1.1778319   0.52600086  1.2667065  -0.03227267\n",
      "  0.7472606   0.41688865 -1.405614   -0.96524596 -0.3139522   1.0063453\n",
      "  0.7510737   0.522592   -0.30218515  0.22849771  1.0321672  -0.04141968\n",
      "  1.5220734   0.5300121   1.0661025  -0.03359783 -0.28075555  0.6141777 ]\n",
      "Vector length: \n",
      " (96,)\n",
      "Word Vector Representation:\n",
      " [-0.43908104 -0.46959737 -0.43020418 -0.076866    1.3814723   0.07770494\n",
      " -0.1157217  -0.71886307 -0.01842186  0.07028738 -1.3842779  -0.29305208\n",
      " -0.57826674 -0.72450614  0.66910744 -0.17112805 -0.728517   -1.4404652\n",
      " -1.5573331   0.0905668  -0.01049708 -0.29841295 -0.5023742   0.21571924\n",
      " -0.03532641 -0.85113394 -1.3917989   0.9816855  -0.13847263 -1.3228017\n",
      "  0.6910312   1.660928   -0.08930665  0.04676402 -0.8261384  -0.33957022\n",
      " -0.6380319   0.00337078  0.6460084  -0.8586641   1.861853    0.04298265\n",
      " -0.6431252  -0.11827445  0.5807551   0.11136992  1.2834818  -0.8017901\n",
      "  0.25335956 -0.33904213 -0.7720748   0.50671554 -0.88833004 -0.3595993\n",
      "  1.5907633  -0.34383476 -1.3195609   0.9147544  -0.5896442  -0.7366767\n",
      " -0.21084075  1.1679434   0.4293813   1.3729328   0.25223264  0.50081956\n",
      " -0.03535065 -0.47836018  0.2126693   2.476964   -0.27344897  0.2891847\n",
      "  0.2619304   0.27140546  0.1042423   1.5299513  -0.65994495  0.45408618\n",
      "  0.08406508 -0.625464   -0.75159013 -1.1533005  -0.32563     0.8923292\n",
      "  0.11851519  0.4931665   0.37189943 -1.255626   -0.39329156  1.2501563\n",
      " -0.24933308 -0.95321834  0.7618495   0.9674322  -0.08899489  1.6124346 ]\n",
      "Vector length: \n",
      " (96,)\n",
      "Word Vector Representation:\n",
      " [ 1.8844086   0.26155928 -0.17495212  0.9136111  -0.10704237 -0.5287219\n",
      " -0.9634075  -0.16404179  0.03572816  0.41840366 -0.07399619  1.4592811\n",
      "  0.48695326 -0.55486536 -0.05709231 -0.92454207  0.1283336   2.2001655\n",
      "  0.40398207 -0.7416624  -0.30303156  0.09293137 -0.07985862 -1.9443433\n",
      "  0.33227724  0.82565254  0.21888794 -0.29165047  0.42192933  0.7292876\n",
      "  0.20009063  1.117863    0.2743305  -0.5611552   0.53124976 -0.9486977\n",
      "  0.8197348  -0.5682528  -1.2979964   1.3448869   0.08099848  1.746279\n",
      " -1.401725    0.69724     0.14004919  1.0478271  -1.6927369   0.17160803\n",
      "  0.687817    0.7599231  -0.6772873   0.68302023  0.17209525  1.832537\n",
      " -0.25243965  0.8348391  -0.8417668   1.4776034  -1.3444874  -0.4091078\n",
      "  0.25952595 -0.92629683  0.08443041 -0.7477812   0.66124654 -1.0684941\n",
      "  0.10954973 -0.31846613 -0.77448314  0.66486377  0.518695    0.52513975\n",
      " -1.3519921   0.22545266 -0.76880646 -0.8428924   0.33362585 -0.22829664\n",
      "  0.149136   -0.6482011  -0.06425516  0.47452956 -0.42819688 -0.02446549\n",
      " -0.3538887   0.06645715  1.5587788  -0.15321374 -1.0424381   0.40930524\n",
      " -0.96860325 -0.5592531   0.5225468  -1.2086749  -0.5715422  -0.73730373]\n",
      "Vector length: \n",
      " (96,)\n",
      "Word Vector Representation:\n",
      " [ 1.137471   -0.95907456 -0.20878527 -0.9746676  -0.90937626  0.61606055\n",
      " -1.014957    1.1448884  -1.1573339  -0.24163961 -1.1791495   0.08562651\n",
      " -0.4271003   0.55771303  0.29363286  0.47789833 -1.2022357  -0.571894\n",
      " -1.0628579  -0.3448493   1.6974971   0.35407662  0.13477075  0.0906049\n",
      " -0.1286402  -1.0549535   0.41799474 -0.23377231  1.9364653   0.45355025\n",
      "  0.6406822  -0.44832945 -0.7422726  -0.76017916 -0.17853177 -0.24783808\n",
      " -0.90338326 -0.2572455  -0.974426    0.50429845 -1.1827009   0.99488246\n",
      "  1.5455155   1.2342594   0.2657406   0.09730083 -1.2551694   0.19298837\n",
      " -0.6359158   0.16327964 -0.09438202 -0.07375781  1.6926959  -1.4352056\n",
      " -0.5522085  -0.3288833   0.72755724  0.9099816   0.02590512 -0.4095296\n",
      " -0.70864856  0.15775293 -0.15772593  0.6830621  -0.7332695  -0.29130423\n",
      "  0.60996765 -0.22555336  0.03751162  0.5023481   1.7247791   0.51022446\n",
      "  0.20997718 -0.6085861   0.27571505 -0.8991639   0.16239482 -2.4123964\n",
      "  0.10411954  0.00710021  0.13041987  0.05639124 -0.8208711  -0.26082912\n",
      " -0.11774644  0.03073229  1.6489023  -0.2811078  -0.29317278  0.666789\n",
      " -0.04422796 -0.48033476  0.8013593   1.100468   -0.5519086   0.37612596]\n",
      "Vector length: \n",
      " (96,)\n",
      "Word Vector Representation:\n",
      " [-0.74123937 -0.75924635  0.5547701   0.17246209 -0.08545439  0.1310436\n",
      "  1.0355792   0.7005582   0.09910601 -0.33157328 -1.1252879  -0.0925982\n",
      " -0.5710443   1.0318756  -0.05989508  0.57397485  0.06617311 -0.7227067\n",
      "  0.0919572   1.071829   -0.75831723  0.560021   -0.292517   -1.2803344\n",
      " -0.06951609 -0.47100502 -0.02026349 -0.34366614 -0.7665709   0.7087782\n",
      "  0.13254938  0.11409858 -0.2870595   0.2679912   0.6755539   0.00321084\n",
      "  0.5368333  -0.26460546 -0.9216622  -1.5472114  -0.9497737   0.50938714\n",
      "  0.40250388  0.2690264  -0.1047824  -0.07045913 -0.61840737 -0.14609331\n",
      " -0.7124269   0.40312076 -0.8019999   0.19450009  0.00356832 -0.6407898\n",
      "  0.89617103 -0.5347624   0.42152458 -0.380927    0.25406274 -0.25227106\n",
      " -0.8449303   0.7971419  -0.5501819   0.03886548  1.5519265   0.33689693\n",
      " -0.46699896 -0.8070442  -0.6856701  -0.46663368  0.8945782   0.94828707\n",
      "  0.99470764  0.24399614  0.18811119 -0.19140564 -0.38144737  0.08100007\n",
      "  0.29313612 -1.5489023   0.09926158 -0.20878625 -0.6514889   0.2128956\n",
      " -0.06698667  0.49385488 -0.3171947  -0.7972943  -0.3419211  -0.5316939\n",
      " -1.1506072  -0.38842756  1.1151583   1.8592203  -0.22334233  1.0116866 ]\n",
      "Vector length: \n",
      " (96,)\n",
      "Word Vector Representation:\n",
      " [ 0.5199621   0.21257253 -0.21301219 -0.47603613  0.2578336  -0.9749868\n",
      "  0.36250478 -0.8546684   0.7090281   0.86648583  0.2889043  -0.76811093\n",
      " -1.2569736  -1.4327233   1.6144778  -0.906448   -1.7950866   1.5809039\n",
      "  1.5127933   1.3197659  -0.69749796 -0.5794342  -0.4245095  -0.82839894\n",
      "  0.5258061  -0.26214775  0.57889473 -0.9647808  -0.48191148  1.1365504\n",
      "  0.29125953 -0.20588596  1.0859779   0.08508521  0.1787658  -0.10773739\n",
      "  0.46457705 -0.44268852  1.6033983  -0.99099636 -0.88028145  0.24450743\n",
      " -0.45305312 -1.171732   -0.07114533 -0.18815142  1.1827773   0.6827868\n",
      "  1.2523239  -1.2452749  -0.63681674  0.01130861  0.57234067  0.3234396\n",
      " -0.43460917 -0.02020893 -0.7885007  -1.1316609   0.5797797  -0.5900429\n",
      " -1.4168912  -1.2495111   0.05177629  0.46725553  0.564771    0.38836637\n",
      "  1.3108169  -0.10702384  0.18042432  0.550376    1.8780738  -0.2541281\n",
      " -0.09155703 -0.3555758  -1.3586178   0.6415794  -0.25393856 -0.1170657\n",
      "  0.19165543 -0.6379458   0.24892998 -0.01478085 -0.00370109  0.5456411\n",
      "  0.47349155 -0.25008053 -0.29793254  1.7148318  -0.5406203   0.8574357\n",
      " -0.50117797 -0.6514913  -0.5226321   0.8106587  -0.10203309  0.04142196]\n",
      "Vector length: \n",
      " (96,)\n",
      "Word Vector Representation:\n",
      " [-7.76780069e-01  1.58006519e-01 -1.14982879e+00 -8.23847353e-02\n",
      "  2.28091836e-01  3.82549286e-01  1.26758742e+00  9.59176421e-01\n",
      " -2.10943982e-01  1.48863316e-01  5.67637444e-01  2.10204720e-03\n",
      "  2.28414178e-01  1.40946400e+00 -1.44752413e-01 -3.82433265e-01\n",
      " -9.38746035e-01 -6.13458514e-01  1.60260415e+00 -5.81712544e-01\n",
      " -6.01745307e-01  8.29485595e-01 -1.32010245e+00 -6.93155050e-01\n",
      "  2.98535049e-01  2.59159207e-02  3.95588398e-01  1.52232969e+00\n",
      " -3.76160443e-03  2.15309858e-03  2.50336915e-01  4.14645225e-01\n",
      "  7.59694815e-01  8.17200959e-01 -8.09504390e-02 -8.49782884e-01\n",
      "  1.38861585e+00  1.79786444e+00 -1.14738083e+00 -3.41659039e-01\n",
      "  2.12092400e-01  1.01988256e-01  1.50461257e-01  2.74664462e-01\n",
      " -6.38203502e-01 -6.72558844e-01 -1.83732665e+00  6.83211684e-02\n",
      " -7.31144667e-01 -5.09929001e-01 -1.88054293e-01  5.88831663e-01\n",
      "  7.13923156e-01 -2.44730473e-01 -8.41996431e-01 -1.46617782e+00\n",
      "  4.91259813e-01  3.70979190e-01  1.25233781e+00 -9.93621290e-01\n",
      " -7.49530196e-02 -1.23752856e+00 -3.66423786e-01 -9.30421531e-01\n",
      " -5.53042173e-01  6.65765405e-02  1.70222133e-01 -7.02304661e-01\n",
      " -6.62757754e-01 -2.94091284e-01  2.32115120e-01 -3.24987292e-01\n",
      "  1.79480314e+00  4.61282611e-01  1.33502078e+00 -4.08502162e-01\n",
      " -4.16939318e-01 -5.29947042e-01 -7.44758785e-01  4.18904006e-01\n",
      "  2.46231556e-02  6.65139258e-01 -1.16853476e+00 -4.57711071e-02\n",
      "  2.42180899e-01  7.00802684e-01 -4.07784618e-02 -1.36447287e+00\n",
      " -1.59245563e+00  1.75956333e+00 -9.85897720e-01  7.68312216e-02\n",
      "  3.31347179e+00  9.82865691e-02 -4.67604101e-01 -2.24320054e-01]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I prefer the morning fight through Denmark\")             # input data\n",
    "for token in doc:\n",
    "    print(\"Vector length: \\n\",token.vector.shape)\n",
    "    print(\"Word Vector Representation:\\n\",token.vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac94d6cc",
   "metadata": {},
   "source": [
    "# Task 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055a4d3f",
   "metadata": {},
   "source": [
    "a) identify the statement is True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6713130e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text= rotten  | Vector= True\n",
      "text= sweet  | Vector= True\n"
     ]
    }
   ],
   "source": [
    "doc = str(nlp(\"Do not put rotten mangoes and sweet oranges together\"))   # input data\n",
    "for token in doc.split():\n",
    "    if token == \"rotten\":\n",
    "        print(\"text=\",nlp(token).text,\" | Vector=\",nlp(token).has_vector)#,\" | OOV=\",nlp(token).is_oov)\n",
    "    if token == \"sweet\":\n",
    "        print(\"text=\",nlp(token).text,\" | Vector=\",nlp(token).has_vector)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f41012d",
   "metadata": {},
   "source": [
    "b) What are the similar values between 'mangoes' and 'orange'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99c18088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mangoes  |  mangoes  |  1.0\n",
      "mangoes  |  orange  |  -0.2636679708957672\n",
      "orange  |  mangoes  |  -0.2636679708957672\n",
      "orange  |  orange  |  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAHID\\AppData\\Local\\Temp\\ipykernel_7152\\1745809704.py:4: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(token1.text,\" | \", token2.text,\" | \", token1.similarity(token2))\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"mangoes orange\")\n",
    "for token1 in doc:\n",
    "    for token2 in doc:\n",
    "        print(token1.text,\" | \", token2.text,\" | \", token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2730055",
   "metadata": {},
   "source": [
    "c) what are the similar values between sweet and oranges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a106589f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sweet  |  sweet  |  1.0\n",
      "sweet  |  oranges  |  0.144328311085701\n",
      "oranges  |  sweet  |  0.144328311085701\n",
      "oranges  |  oranges  |  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAHID\\AppData\\Local\\Temp\\ipykernel_7152\\4240221294.py:4: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(token1.text,\" | \", token2.text,\" | \", token1.similarity(token2))\n"
     ]
    }
   ],
   "source": [
    "doc=nlp('sweet oranges')\n",
    "for token1 in doc:\n",
    "    for token2 in doc:\n",
    "        print(token1.text,\" | \", token2.text,\" | \", token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d44d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
